{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**neuron functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def exp(z):\n",
    "    return np.exp(z)\n",
    "\n",
    "def I(z): # identity function\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss/Cost functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAPE(pred, tgt):\n",
    "    N = tgt.shape[0]\n",
    "    I = tgt > 0\n",
    "    tgt = tgt[I]\n",
    "    pred = pred[I]\n",
    "    return np.sum(np.divide(np.abs(pred - tgt), tgt)) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**derivative functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d(a, f):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        a: a matrix of activations, a = f(z) for some input matrix z\n",
    "        f: a function such that f(z) = a\n",
    "    What it does:\n",
    "        determines a' = df(z)/dz, the derivative of a with respect to z.\n",
    "        For example, if a = exp(z) then a' = a.\n",
    "    Outputs:\n",
    "        the derivative of a with respect to z\n",
    "    \"\"\"\n",
    "    return (np.ones_like(a) if f == I else\n",
    "           np.sign(a) if f == relu else\n",
    "           a*(1 - a) if f == sigmoid else\n",
    "           a if f == exp else ValueError('bad function type'))\n",
    "\n",
    "def dMAPE(pred, tgt):\n",
    "    N = tgt.shape[0]\n",
    "    return np.divide( np.multiply(tgt, np.sign(pred - tgt)), N*(np.multiply(tgt, tgt) + np.finfo(float).eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**randomization functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Gauss(n, s):\n",
    "    return n*(1 + np.random.randn()/s)\n",
    "\n",
    "def asymptotic(n, s):\n",
    "    return 1 - (1 - n)/(1 + np.random.randn()/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, sizes, flavors, eta, alpha, batch_size, epochs, loss, max_inputs):\n",
    "        np.random.seed(1729)\n",
    "        self.sizes = sizes # number of nodes in each layer, including input layer\n",
    "        self.sizes[0] = min(self.sizes[0], max_inputs)\n",
    "        self.flavors = flavors # function executed by nodes in given layer, excluding input layer\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss = loss\n",
    "        self.max_inputs = max_inputs\n",
    "        self.weights = self.__get_weights__()\n",
    "        self.biases = self.__get_biases__()\n",
    "        \n",
    "    def __get_weights__(self):\n",
    "        return [np.matrix(0.01*np.random.rand(fro, to)) \n",
    "                for (to, fro) in zip(self.sizes[1:], self.sizes[:-1])]\n",
    "\n",
    "    def __get_biases__(self):\n",
    "        return [np.matrix(0.01*np.random.rand(to, 1)).T for to in self.sizes[1:]]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            X: a matrix containing rows of input vectors\n",
    "        What it does:\n",
    "            Ths is the feed forward algorithm, It iterates through the network object, \n",
    "            updating the input vector X at each layer of the network using the weights, \n",
    "            biases and node function\n",
    "        Outputs:\n",
    "            a list of matrices corresponding to the activations at each layer of\n",
    "            the matrix. For example, the first matrix is the input matrix, the last\n",
    "            matrix is the prediction matrix. Intermediate matrices are the\n",
    "            activations output by the hidden layers\n",
    "        \"\"\"\n",
    "        A = [X]\n",
    "        for i in xrange(len(self.flavors)):\n",
    "            W, B, F = self.weights[i], self.biases[i], self.flavors[i]\n",
    "            X = F(X*W + B)\n",
    "            A.append(X)\n",
    "        return A\n",
    "            \n",
    "    def __backprop__(self, A, Y):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            A: a list containing matrices of activations for each layer of the\n",
    "            network for the current minibatch\n",
    "            Y: a list of targets for the curent minibatch\n",
    "        What it does:\n",
    "            given a batch of data, finds the gradients of the loss function\n",
    "            with respect to each of the weight and bias matrices\n",
    "        Outputs:\n",
    "            a list containing all partials with respect to weight matrices\n",
    "            and a list containing all partials with respect to bias matrices\n",
    "        \"\"\"\n",
    "        nabla_CB, nabla_CW = [], []\n",
    "        delta = dMAPE(A[-1], Y)\n",
    "        seno = np.ones_like(Y).T # row ones vector\n",
    "        for i in xrange(1, len(A)):\n",
    "            # calculate z-derivative of current activation\n",
    "            da = d(A[-i], self.flavors[-i])\n",
    "            delta_da = np.multiply(delta, da)\n",
    "            nabla_CB.insert(0, seno*delta_da)\n",
    "            nabla_CW.insert(0, A[-i-1].T*(delta_da))\n",
    "            delta = (delta_da)*self.weights[-i].T\n",
    "        return nabla_CB, nabla_CW\n",
    "    \n",
    "    def train(self, X_fit, Y_fit):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            X_fit: the portion of the training feature matrix used for fitting\n",
    "            Y_fit:  the portion of the training target matrix used for fitting\n",
    "            X_val: the portion of the training feature matrix used for validation\n",
    "        What it does:\n",
    "            Iterates over epochs in which the entire fit data matrix is used to\n",
    "            train the network. Controls the batch generation and selection within\n",
    "            epochs. Feeds batches one at a time into the feedforward and\n",
    "            backpropagation functions. Updates the network object's weights and\n",
    "            biases with the negative gradients derived by back prop and scaled by\n",
    "            the learning rate factor. Decays the learning rate each epoch.\n",
    "        Outputs:\n",
    "            an array of predictions for the validation data from the fully trained\n",
    "            network\n",
    "        \"\"\"\n",
    "        np.random.seed(1729)\n",
    "        eta = self.eta # make a copy as we're gonna decay it over time\n",
    "        for ep in xrange(self.epochs):\n",
    "            n = X_fit.shape[0]\n",
    "            indices = np.random.shuffle([i for i in xrange(n)])\n",
    "            batches = n / self.batch_size + 1 # cld --> ceiling division\n",
    "            batch_size = 1.*n / batches # the used batch size is not precisely what\n",
    "                                     # was requested, but optimal given the\n",
    "                                     # amount of data\n",
    "            k = 0\n",
    "            while k < batches:\n",
    "                lo = int(k*batch_size)\n",
    "                hi = int((k+1)*batch_size)\n",
    "                A_list = self.predict(X_fit[lo:hi,:])\n",
    "                nabla_CB, nabla_CW = self.__backprop__(A_list, Y_fit[lo:hi])\n",
    "                self.weights = ([w - eta*dCw for (w, dCw) in zip(self.weights, nabla_CW)])\n",
    "                self.biases = ([b - eta*dCb for (b, dCb) in zip(self.biases, nabla_CB)])\n",
    "                k += 1\n",
    "            eta *= self.alpha\n",
    "\n",
    "    def HyparamGen(self):\n",
    "        np.random.seed()\n",
    "        self.sizes = [int(Gauss(sz, 10)) for sz in self.sizes[0:-1]] + [1] # 1 on end\n",
    "        self.sizes[0] = min(self.sizes[0], self.max_inputs)\n",
    "        self.eta = Gauss(self.eta, 10)\n",
    "        self.alpha = asymptotic(self.alpha, 10)\n",
    "        self.epochs = int(Gauss(self.epochs, 10))\n",
    "        np.random.seed(1729)\n",
    "        self.weights = self.__get_weights__()\n",
    "        self.biases = self.__get_biases__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_features(X, Y):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        X: the full feature matrix\n",
    "        Y: the full target matrix\n",
    "    What it does:\n",
    "        Finds the top features (columns) in the training feature matrix according to \n",
    "        correlation to the training target matrix.\n",
    "    Outputs:\n",
    "        the indices of the feature columns in order of correlation importance\n",
    "    \"\"\"\n",
    "    lyste = abs(X.T * Y)\n",
    "    indices = []\n",
    "    for _ in xrange(len(lyste)):\n",
    "        i = np.argmax(lyste)\n",
    "        lyste[i] = 0.\n",
    "        indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CrossValidation(net, X_train, Y_train, X_test, Y_test, CV):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        net: a neural network object\n",
    "        X_train: the training feature matrix\n",
    "        Y_train: the training target matrix\n",
    "        X_test: the test feature matrix\n",
    "        Y_test: the test target matrix\n",
    "        CV: an array of arrays containg the fit and train indices for each\n",
    "        cross-validation fold\n",
    "    What it does:\n",
    "        Iterates over cross-validation folds, splitting the data into\n",
    "        appropriate fit and validation sets, and passing the fit and val sets\n",
    "        on to the train function. Assembles validation predictions from the\n",
    "        train function into a comprehensive list over the entire training data\n",
    "        set. Assembles test data predictions from the feedforward function for\n",
    "        every fold.\n",
    "    Outputs:\n",
    "        The validation loss, using whatever loss functon is defined for the\n",
    "        network\n",
    "        The mean of the test data predictions from each fold of the cross\n",
    "        validation\n",
    "    \"\"\"\n",
    "    psi = np.matrix(np.empty((0, 1)))\n",
    "    Y = np.matrix(np.empty((0, 1)))\n",
    "    psi_test = np.matrix(np.empty((X_test.shape[0], 0)))\n",
    "    for in_fit, in_val in CV:\n",
    "        X_fit, Y_fit = X_train[in_fit,:], Y_train[in_fit]\n",
    "        X_val, Y_val = X_train[in_val,:], Y_train[in_val]\n",
    "        #training\n",
    "        net.train(X_fit, Y_fit)\n",
    "        psi = np.vstack((psi, net.predict(X_val)[-1]))\n",
    "        Y = np.vstack((Y, Y_val))\n",
    "        psi_test = np.hstack((psi_test, net.predict(X_test)[-1]))\n",
    "    return (net.loss(psi, Y), net.loss(np.mean(psi_test, axis=1), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the perpetual grid search algorithm, It will not terminate until you interrupt it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "import copy\n",
    "\n",
    "def PerpetualSearch(net, X, Y, aktuellMAPE):\n",
    "    folds = 3\n",
    "    correlindices = top_features(X, Y)\n",
    "    np.random.seed(1729)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "    CVfolds = KFold(Y_train.shape[0], folds, shuffle=True)\n",
    "    optimal_net = copy.deepcopy(net)\n",
    "    while True:\n",
    "        print \"doing something\"\n",
    "        # focus on top N features\n",
    "        tops = correlindices[0:net.sizes[0]]\n",
    "        X_train_tops, X_test_tops = X_train[:,tops], X_test[:,tops]\n",
    "        currentMAPE, pseudo_testMAPE = CrossValidation(net, X_train_tops, Y_train, \n",
    "                                                       X_test_tops, Y_test, CVfolds)\n",
    "        with open(\"Record.csv\",\"a+\") as f:\n",
    "            for i in range(6):\n",
    "                if i < len(net.sizes)-1:\n",
    "                    f.write(\"%s\\t\" % net.sizes[i])\n",
    "            f.write(\"%s\\t\" % net.eta)\n",
    "            f.write(\"%s\\t\" % net.alpha)\n",
    "            f.write(\"%s\\t\" %net.epochs)\n",
    "            f.write(\"%s\\t\" % currentMAPE)\n",
    "            f.write(\"%s\\t\" % pseudo_testMAPE)\n",
    "            if currentMAPE < aktuellMAPE:\n",
    "                net.train(X_train_tops, Y_train)\n",
    "                true_test_loss = net.loss(net.predict(X_test_tops)[-1], Y_test)\n",
    "                f.write(\"%s\\n\" % true_test_loss)  \n",
    "                optimal_net = copy.deepcopy(net)\n",
    "                aktuellMAPE = currentMAPE\n",
    "            else:\n",
    "                f.write(\"\\n\")\n",
    "        net = copy.deepcopy(optimal_net)\n",
    "        net.HyparamGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('TrainingData.csv')\n",
    "\n",
    "Y = np.matrix(training_data.iloc[:,2].values).T\n",
    "X = np.matrix(training_data.iloc[:,3:].values)\n",
    "\n",
    "training_data = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1729) # ensures test labels are identical to those in grid search\n",
    "_,_, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "_ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the guess-1 result for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26865339812767497"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess1 = np.ones_like(Y_test)\n",
    "MAPE(guess1, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the guess-0 result for the validation (training) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26715048000148989"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess1 = np.ones_like(Y_train)\n",
    "MAPE(guess1, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess, Y_train, Y_test = 0, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-9387ae8a5552>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-9387ae8a5552>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    if i < len(net.sizes)-1\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "correlindices = top_features(X, Y)\n",
    "np.random.seed(1729)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "CVfolds = KFold(Y_train.shape[0], folds, shuffle=True)\n",
    "aktuellMAPE = np.infty\n",
    "\n",
    "for w in [[10,10,10,10], [20,20,20,20], [50,50,50,50], [100,100,100,100]]:\n",
    "    for eta in [0.1, 0.5, 1]:\n",
    "        for alpha in [0.999, 0.99, 0.9]:\n",
    "            for eps in [100, 200, 300, 400]:\n",
    "                net = Network(\n",
    "                              w + [1],          # nodes per layer\n",
    "                              [relu, relu, relu, relu],     # activation functions at each hidden and output layer\n",
    "                              eta,                                     # learning rate\n",
    "                              alpha,                                    # learning rate decay\n",
    "                              2048,                                    # desired batch size\n",
    "                              eps,                                     # number of epochs\n",
    "                              MAPE,                                    # loss function\n",
    "                              X.shape[1]                               # max number of features\n",
    "                             )\n",
    "                print \"doing something\"\n",
    "                # focus on top N features\n",
    "                tops = correlindices[0:net.sizes[0]]\n",
    "                X_train_tops, X_test_tops = X_train[:,tops], X_test[:,tops]\n",
    "                currentMAPE, pseudo_testMAPE = CrossValidation(net, X_train_tops, Y_train, \n",
    "                                                       X_test_tops, Y_test, CVfolds)\n",
    "                with open(\"Record.csv\",\"a+\") as f:\n",
    "                    for sz in net.sizes[:-1]:\n",
    "                        f.write(\"%s\\t\" % sz)\n",
    "                    f.write(\"%s\\t\" % net.eta)\n",
    "                    f.write(\"%s\\t\" % net.alpha)\n",
    "                    f.write(\"%s\\t\" %net.epochs)\n",
    "                    f.write(\"%s\\t\" % currentMAPE)\n",
    "                    f.write(\"%s\\t\" % pseudo_testMAPE)\n",
    "                    if currentMAPE < aktuellMAPE:\n",
    "                        net.train(X_train_tops, Y_train)\n",
    "                        true_test_loss = net.loss(net.predict(X_test_tops)[-1], Y_test)\n",
    "                        f.write(\"%s\\n\" % true_test_loss)  \n",
    "                        optimal_net = copy.deepcopy(net)\n",
    "                        aktuellMAPE = currentMAPE\n",
    "                    else:\n",
    "                        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8f58a47b46e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-9b8dd04aac57>\u001b[0m in \u001b[0;36mGridSearch\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mX_train_tops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_tops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         currentMAPE, pseudo_testMAPE = CrossValidation(net, X_train_tops, Y_train, \n\u001b[1;32m---> 32\u001b[1;33m                                                        X_test_tops, Y_test, CVfolds)\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Record.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a+\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-9500ea51b193>\u001b[0m in \u001b[0;36mCrossValidation\u001b[1;34m(net, X_train, Y_train, X_test, Y_test, CV)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mpsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6f50e0624167>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X_fit, Y_fit)\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mA_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mnabla_CB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_CW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__backprop__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdCw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdCw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_CW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdCb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdCb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_CB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize network object as starting point for grid search\n",
    "record = pd.read_csv('Record.csv', delimiter='\\t')\n",
    "i = np.argmin(record[\"Val MAPE\"])\n",
    "aktuellMAPE = record.iloc[i, 9]\n",
    "net = Network(\n",
    "              [int(n) for n in (record.iloc[i, 0:4].values)] + [1], # nodes per layer\n",
    "              [relu, relu, relu, relu],         # activation functions at each hidden and output layer\n",
    "              record.iloc[i, 6],                # learning rate\n",
    "              record.iloc[i, 7],                # learning rate decay\n",
    "              2048,                             # desired batch size\n",
    "              int(record.iloc[i, 8]),           # number of epochs\n",
    "              MAPE,                             # loss function\n",
    "              X.shape[1]                        # max number of features\n",
    "             )\n",
    "net.HyparamGen()\n",
    "\n",
    "PerpetualSearch(net, X, Y, aktuellMAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check stability with respect to train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-653de7839da5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mX_train_tops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_tops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     currentMAPE, pseudo_testMAPE = CrossValidation(net, X_train_tops, Y_train, \n\u001b[1;32m---> 26\u001b[1;33m                                            X_test_tops, Y_test, CVfolds)\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Stability.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a+\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-9500ea51b193>\u001b[0m in \u001b[0;36mCrossValidation\u001b[1;34m(net, X_train, Y_train, X_test, Y_test, CV)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mpsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6f50e0624167>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X_fit, Y_fit)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mlo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mA_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[0mnabla_CB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_CW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__backprop__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdCw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdCw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_CW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6f50e0624167>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflavors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflavors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/robert/anaconda2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[1;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__rmul__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p = 1729\n",
    "while True:\n",
    "    p += 1\n",
    "    np.random.seed(p)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "    folds = 3\n",
    "    CVfolds = KFold(Y_train.shape[0], folds, shuffle=True)\n",
    "    record = pd.read_csv('Record.csv', delimiter='\\t')\n",
    "    i = np.argmin(record[\"Val MAPE\"])\n",
    "    net = Network(\n",
    "                  [int(n) for n in (record.iloc[i, 0:4].values)] + [1], # nodes per layer\n",
    "                  [relu, relu, relu, relu],         # activation functions at each hidden and output layer\n",
    "                  record.iloc[i, 6],                # learning rate\n",
    "                  record.iloc[i, 7],                # learning rate decay\n",
    "                  2048,                             # desired batch size\n",
    "                  int(record.iloc[i, 8]),           # number of epochs\n",
    "                  MAPE,                             # loss function\n",
    "                  X.shape[1]                        # max number of features\n",
    "                 )\n",
    "    print \"doing something\"\n",
    "    # focus on top N features\n",
    "    correlindices = top_features(X, Y)\n",
    "    tops = correlindices[0:net.sizes[0]]\n",
    "    X_train_tops, X_test_tops = X_train[:,tops], X_test[:,tops]\n",
    "    currentMAPE, pseudo_testMAPE = CrossValidation(net, X_train_tops, Y_train, \n",
    "                                           X_test_tops, Y_test, CVfolds)\n",
    "    with open(\"Stability.csv\",\"a+\") as f:\n",
    "        for sz in net.sizes[:-1]:\n",
    "            f.write(\"%s\\t\" % sz)\n",
    "        f.write(\"%s\\t\" % net.eta)\n",
    "        f.write(\"%s\\t\" % net.alpha)\n",
    "        f.write(\"%s\\t\" %net.epochs)\n",
    "        f.write(\"%s\\t\" % currentMAPE)\n",
    "        f.write(\"%s\\t\" % pseudo_testMAPE)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in a few more layers to the best model to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing something\n",
      "doing something\n",
      "doing something\n",
      "doing something\n"
     ]
    }
   ],
   "source": [
    "# initialize network object as starting point for grid search\n",
    "record = pd.read_csv('Record.csv', delimiter='\\t')\n",
    "i = np.argmin(record[\"Val MAPE\"])\n",
    "aktuellMAPE = record.iloc[i, 9]\n",
    "net = Network(\n",
    "              [int(n) for n in (record.iloc[i, 0:4].values)] + \n",
    "                        [int(n) for n in (record.iloc[i, 2:4].values)] + [1], # add in two more layers\n",
    "              [relu, relu, relu, relu, relu, relu],         # activation functions at each hidden and output layer\n",
    "              record.iloc[i, 6],                # learning rate\n",
    "              record.iloc[i, 7],                # learning rate decay\n",
    "              2048,                             # desired batch size\n",
    "              int(record.iloc[i, 8]),           # number of epochs\n",
    "              MAPE,                             # loss function\n",
    "              X.shape[1]                        # max number of features\n",
    "             )\n",
    "net.HyparamGen()\n",
    "\n",
    "PerpetualSearch(net, X, Y, np.infty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
